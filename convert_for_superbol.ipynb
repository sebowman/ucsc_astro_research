{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reads in photometry data in the format of CSV files from The Open Supernova Catalog, and CSV files output by my DOLPHOT-scraping script dolphot_retrieval_finalized.py and converts it to text files for input into Matt Nicholl's superbol.py program (code and documentation found here https://github.com/mnicholl/superbol).\n",
    "\n",
    "The code takes as input the data from both sources, and the luminosity distance lum_d in Mpc (labelled d_L on the sne.space page for each SN). It subtracts the distance modulus (5log10(lum_d(10^6)/10)) and foreground galactic extinction (which must be looked up and added into the code by the user) from each magnitude value,  and converts the data into text files of the format 'MJD    filter1_mag    filter1_uncertainty    filter2_mag    filter2_uncertainty ... '.  The text files are named in the format 'SNname_filters.txt', for example 'SN2006aj_ugriz.txt' or 'iPTF13bvn_JHK.txt'.\n",
    "\n",
    "It also collects the sources of each sne.space data set used for referencing purposes.\n",
    "\n",
    "The code contains a function to perform this analysis and formatting specific to each SN, so the user will need to edit the code for use with data from other SNe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import numpy as np \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from astropy.time import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from The Open Supernova Catalog (input correct filenames or paths)\n",
    "iPTF13bvn = pd.read_csv('sne_space_photometry_data/iPTF13bvn_photometry.txt')\n",
    "SN2006aj = pd.read_csv('sne_space_photometry_data/SN2006aj_photometry.txt')\n",
    "SN2007uy = pd.read_csv('sne_space_photometry_data/SN2007uy_photometry.txt')\n",
    "SN1993J = pd.read_csv('sne_space_photometry_data/SN1993J_photometry.txt')\n",
    "\n",
    "#read in data scraped from dolphot (input correct filenames or paths)\n",
    "iPTF13bvn_lt = pd.read_csv('phot_plot_data_iPTF13bvn_old.csv')\n",
    "SN1993J_lt = pd.read_csv('phot_plot_data_SN1993J_old.csv')\n",
    "SN2007uy_lt = pd.read_csv('phot_plot_data_2007uy.csv')\n",
    "SN2006aj_lt = pd.read_csv('phot_plot_data_2006aj.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells define and then evaluate a function to analyze and format the data from both sources into two separate text files for one specific SN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to format both data sets for iPTF13bvn\n",
    "def format_for_superbol_iPTF13bvn(data, data_lt, lum_d):\n",
    "    \n",
    "    srcs = []\n",
    "    \n",
    "    #remove unneccesary column from sne.space data\n",
    "    data.drop(['upperlimit'], axis=1)\n",
    "    \n",
    "    #remove data points with no associated error from sne.space data\n",
    "    data = data[data.e_magnitude > 0]\n",
    "    \n",
    "    #select desired filters from sne.space data\n",
    "    data = data[data.band.isin(['B', 'V', 'UVW2','I'])]\n",
    "    \n",
    "    #round datetime stamp to the day\n",
    "    data.time = np.round(data.time, 0)\n",
    "    \n",
    "    #convert dates from dolphot data to MJD\n",
    "    newcol = []    \n",
    "    for i in data_lt.date_obs:\n",
    "        newcol.append(np.round(Time(i+'T00:00:00.000').mjd,0))\n",
    "    data_lt['time'] = newcol\n",
    "    \n",
    "    #calculate distance modulus and print (will need as input for superbol)\n",
    "    dmod = (5*np.log10(lum_d*(10**6)/10.))\n",
    "    print(dmod)\n",
    "    \n",
    "    #list sources of data taken from sne.space, for referencing purposes\n",
    "    for x in data['source']:\n",
    "        if x not in srcs:\n",
    "            srcs.append(x)\n",
    "            \n",
    "    #format sne.space data and write to a text file\n",
    "    file1 = open('iPTF13bvn_UBVI.txt', 'w+')      \n",
    "     \n",
    "    #group by observation date\n",
    "    for k in data.time.unique():\n",
    "        j = data[data.time == k]\n",
    "\n",
    "        #select the data in this filter and average the magnitudes and magnitude uncertainties\n",
    "        #for each observation date \n",
    "        b = j[j.band == 'B']\n",
    "        B = np.average(b['magnitude'])\n",
    "        B_err= np.average(b['e_magnitude'])\n",
    "        #subtract the foreground galactic extinction for this filter and host galaxy, \n",
    "        #and the distance modulus for this object\n",
    "        B = B - 0.184 - dmod\n",
    "\n",
    "        #follow the same process for the other filters        \n",
    "        v = j[j.band == 'V']\n",
    "        V = np.average(v['magnitude'])\n",
    "        V_err = np.average(v['e_magnitude'])\n",
    "        V = V - 0.139 - dmod    \n",
    "\n",
    "        u = j[j.band == 'UVW2']\n",
    "        U = np.average(u['magnitude'])\n",
    "        U_err = np.average(u['e_magnitude'])\n",
    "        U = U - 0.220 - dmod\n",
    "\n",
    "        i = j[j.band == 'I']\n",
    "        I = np.average(i['magnitude'])\n",
    "        I_err = np.average(i['e_magnitude'])\n",
    "\n",
    "        #write to a tab delimited text file\n",
    "        file1.writelines([str(k)+'\\t', str(U)+'\\t', str(U_err)+'\\t', str(B)+'\\t', str(B_err)+'\\t', str(V)+'\\t', str(V_err)+'\\t', str(I)+'\\t', str(I_err)+'\\t \\n'])    \n",
    "    \n",
    "    file1.close()\n",
    "     \n",
    "    #follow the same process as above to format dolphot data and write to a separate text file\n",
    "    file2 = open('iPTF13bvnlt_UBVI.txt', 'w+')  \n",
    "        \n",
    "    for k in data_lt.time.unique():\n",
    "        j = data_lt[data_lt.time == k]\n",
    "\n",
    "        b = j[j.band.isin(['Extremely wide blue','WFPC2 B'])]\n",
    "        B = np.average(b['m_avg'])\n",
    "        B = B - 0.173 - dmod\n",
    "        B_err= np.average(b['sigma_m_avg'])\n",
    "\n",
    "        v = j[j.band == 'WFPC2 V']\n",
    "        V = np.average(v['m_avg'])\n",
    "        V = V - 0.145 - dmod\n",
    "        V_err = np.average(v['sigma_m_avg'])    \n",
    "\n",
    "        u = j[j.band == 'UV wide']\n",
    "        U = np.average(u['m_avg'])\n",
    "        U = U - 0.355 - dmod\n",
    "        U_err = np.average(u['sigma_m_avg'])\n",
    "\n",
    "        i = j[j.band == 'Wfpc 2 Wide I']\n",
    "        I = np.average(i['m_avg'])\n",
    "        I = I - 0.078 - dmod\n",
    "        I_err = np.average(i['sigma_m_avg'])  \n",
    "\n",
    "        file2.writelines([str(k)+'\\t', str(U)+'\\t', str(U_err)+'\\t', str(B)+'\\t', str(B_err)+'\\t', str(V)+'\\t', str(V_err)+'\\t', str(I)+'\\t', str(I_err)+'\\t \\n'])    \n",
    "    \n",
    "\n",
    "    file2.close()\n",
    "    \n",
    "    #print references\n",
    "    return srcs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.498625769878185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2016A&A...593A..68F', '2016ApJ...825L..22F', '2014Ap&SS.354...89B']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate function to create text files for iPTF13bvn sne.space and dolphot photometry data\n",
    "#(input names of data files read in at beginning of notebook, and luminosity distance from \n",
    "#sne.space) and print reference codes\n",
    "format_for_superbol_iPTF13bvn(iPTF13bvn, iPTF13bvn_lt, 19.94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below follow a similar process for a few more SNe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_superbol_1993J(data, data_lt, lum_d):\n",
    "    \n",
    "    srcs = []\n",
    "    \n",
    "    data.drop(['upperlimit','instrument','telescope'], axis=1)\n",
    "    #instead of removing data with no associated uncertainty, assign a value of 0.1 to the uncertainty for that data\n",
    "    data = data.fillna(0.1)\n",
    "    \n",
    "    data = data[data.band.isin(['U','B', 'V', 'R','I'])]\n",
    "    data.time = np.round(data.time, 0)\n",
    "    \n",
    "    newcol = []    \n",
    "    for i in data_lt.date_obs:\n",
    "        newcol.append(np.round(Time(i+'T00:00:00.000').mjd,0))\n",
    "    data_lt['time'] = newcol\n",
    "    \n",
    "    dmod = (5*np.log10(lum_d*(10**6)/10.))\n",
    "    print(dmod)\n",
    "    \n",
    "    for x in data['source']:\n",
    "        if x not in srcs:\n",
    "            srcs.append(x)\n",
    "\n",
    "    file1 = open('SN1993J_UBVRI.txt', 'w+')      \n",
    "        \n",
    "    for k in data.time.unique():\n",
    "        j = data[data.time == k]\n",
    "\n",
    "        u = j[j.band == 'U']\n",
    "        U = np.average(u['magnitude'])\n",
    "        U = U - 0.348 - dmod\n",
    "        U_err = np.average(u['e_magnitude'])\n",
    "\n",
    "        b = j[j.band == 'B']\n",
    "        B = np.average(b['magnitude'])\n",
    "        B = B - 0.291 - dmod\n",
    "        B_err= np.average(b['e_magnitude'])\n",
    "\n",
    "        v = j[j.band == 'V']\n",
    "        V = np.average(v['magnitude'])\n",
    "        V = V - 0.220 - dmod\n",
    "        V_err = np.average(v['e_magnitude'])    \n",
    "\n",
    "        r = j[j.band == 'R']\n",
    "        R = np.average(r['magnitude'])\n",
    "        R = R - 0.174 - dmod\n",
    "        R_err = np.average(r['e_magnitude'])\n",
    "\n",
    "        i = j[j.band == 'I']\n",
    "        I = np.average(i['magnitude'])\n",
    "        I = I - 0.121 - dmod\n",
    "        I_err = np.average(i['e_magnitude'])  \n",
    "\n",
    "        file1.writelines([str(k)+'\\t', str(U)+'\\t', str(U_err)+'\\t', str(B)+'\\t', str(B_err)+'\\t', str(V)+'\\t', str(V_err)+'\\t', str(R)+'\\t', str(R_err)+'\\t', str(I)+'\\t', str(I_err)+'\\t \\n'])    \n",
    "    \n",
    "    file1.close()\n",
    "        \n",
    "    file2 = open('SN1993Jlt_UBVRI.txt', 'w+')  \n",
    "        \n",
    "    for k in data_lt.time.unique():\n",
    "        j = data_lt[data_lt.time == k]\n",
    "        \n",
    "        u = j[j.band == 'ISM feature']\n",
    "        U = np.average(u['m_avg'])\n",
    "        U = U - 0.622 - dmod\n",
    "        U_err = np.average(u['sigma_m_avg'])\n",
    "        \n",
    "        b = j[j.band == 'WFPC2 B']\n",
    "        B = np.average(b['m_avg'])\n",
    "        B = B - 0.291 - dmod\n",
    "        B_err= np.average(b['sigma_m_avg'])\n",
    "\n",
    "        v = j[j.band == 'WFPC2 V']\n",
    "        V = np.average(v['m_avg'])\n",
    "        V = V - 0.229 - dmod\n",
    "        V_err = np.average(v['sigma_m_avg'])    \n",
    "\n",
    "        r = j[j.band == 'SDSS r']\n",
    "        R = np.average(r['m_avg'])\n",
    "        R = R - 0.181 - dmod\n",
    "        R_err = np.average(r['sigma_m_avg'])\n",
    "\n",
    "        i = j[j.band == 'WFPC2 wide I']\n",
    "        I = np.average(i['m_avg'])\n",
    "        I = I - 0.124 - dmod\n",
    "        I_err = np.average(i['sigma_m_avg'])  \n",
    "\n",
    "        file2.writelines([str(k)+'\\t', str(U)+'\\t', str(U_err)+'\\t', str(B)+'\\t', str(B_err)+'\\t', str(V)+'\\t', str(V_err)+'\\t', str(R)+'\\t', str(R_err)+'\\t',str(I)+'\\t', str(I_err)+'\\t \\n'])    \n",
    "    \n",
    "\n",
    "    file2.close()\n",
    "    \n",
    "    return srcs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.311989989494784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:356: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1995A&AS..110..513B,SUSPECT',\n",
       " '1996AJ....112..732R,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1994AJ....107.1022R,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1994supe.conf...27L,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1994AJ....107.1022R,1994supe.conf...27L,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1995A&AS..110..513B,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1994AJ....107.1453B,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1993PASJ...45L..59V,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1993PASJ...45L..63O,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1995PAZh...21..670M,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1994supe.conf...27L,1994AJ....107.1453B,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1994AJ....107.1022R,1994AJ....107.1453B,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1993IAUC.5796....1M,Sternberg Astronomical Institute Supernova Light Curve Catalogue',\n",
       " '1993IAUC.5782....1Z,Sternberg Astronomical Institute Supernova Light Curve Catalogue']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_for_superbol_1993J(SN1993J,SN1993J_lt,2.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_superbol_2007uy(data, data_lt, lum_d):\n",
    "    \n",
    "    srcs = []\n",
    "    \n",
    "    data.drop(['upperlimit'], axis=1)\n",
    "    data = data[data.e_magnitude > 0]\n",
    "    \n",
    "    data = data[data.band.isin(['V',\"i'\"])]\n",
    "    data.time = np.round(data.time, 0)\n",
    "    \n",
    "    newcol = []    \n",
    "    for i in data_lt.date_obs:\n",
    "        newcol.append(np.round(Time(i+'T00:00:00.000').mjd,0))\n",
    "    data_lt['time'] = newcol\n",
    "    \n",
    "    dmod = (5*np.log10(lum_d*(10**6)/10.))\n",
    "    print(dmod)\n",
    "    \n",
    "    for x in data['source']:\n",
    "        if x not in srcs:\n",
    "            srcs.append(x)\n",
    "\n",
    "    file1 = open('SN2007uy_VI.txt', 'w+')      \n",
    "        \n",
    "    for k in data.time.unique():\n",
    "        j = data[data.time == k]\n",
    "\n",
    "        v = j[j.band == 'V']\n",
    "        V = np.average(v['magnitude'])\n",
    "        V = V - 0.062 - dmod\n",
    "        V_err = np.average(v['e_magnitude'])    \n",
    "\n",
    "        i = j[j.band == \"i'\"]\n",
    "        I = np.average(i['magnitude'])\n",
    "        I = I - 0.038 - dmod\n",
    "        I_err = np.average(i['e_magnitude'])  \n",
    "\n",
    "        file1.writelines([str(k)+'\\t', str(V)+'\\t', str(V_err)+'\\t', str(I)+'\\t', str(I_err)+'\\t \\n'])    \n",
    "    \n",
    "    file1.close()\n",
    "        \n",
    "    file2 = open('SN2007uylt_VI.txt', 'w+')  \n",
    "        \n",
    "    for k in data_lt.time.unique():\n",
    "        j = data_lt[data_lt.time == k]\n",
    "\n",
    "        v = j[j.band == 'WFPC2 V']\n",
    "        V = np.average(v['m_avg'])\n",
    "        V = V - 0.064 - dmod\n",
    "        V_err = np.average(v['sigma_m_avg'])    \n",
    "\n",
    "        i = j[j.band == 'WFPC2 wide I']\n",
    "        I = np.average(i['m_avg'])\n",
    "        I = I - 0.035 - dmod\n",
    "        I_err = np.average(i['sigma_m_avg'])  \n",
    "\n",
    "        file2.writelines([str(k)+'\\t', str(V)+'\\t', str(V_err)+'\\t', str(I)+'\\t', str(I_err)+'\\t \\n'])    \n",
    "    \n",
    "\n",
    "    file2.close()\n",
    "    \n",
    "    return srcs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.07486673985409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2014ApJS..213...19B', '2014Ap&SS.354...89B']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_for_superbol_2007uy(SN2007uy,SN2007uy_lt,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_superbol_2006aj(data, data_lt, lum_d):\n",
    "    \n",
    "    srcs = []\n",
    "    \n",
    "    data.drop(['upperlimit'], axis=1)\n",
    "    data = data[data.e_magnitude > 0]\n",
    "    \n",
    "    data = data[data.band.isin(['B', 'V', \"r'\",\"i'\"])]\n",
    "    data.time = np.round(data.time, 0)\n",
    "    \n",
    "    newcol = []   \n",
    "    for i in data_lt.date_obs:\n",
    "        newcol.append(np.round(Time(i+'T00:00:00.000').mjd,0))\n",
    "    data_lt['time'] = newcol\n",
    "    \n",
    "    dmod = (5*np.log10(lum_d*(10**6)/10.))\n",
    "    print(dmod)\n",
    "    \n",
    "    for x in data['source']:\n",
    "        if x not in srcs:\n",
    "            srcs.append(x)\n",
    "\n",
    "    file1 = open('SN2006aj_BVRI.txt', 'w+')      \n",
    "        \n",
    "    for k in data.time.unique():\n",
    "        j = data[data.time == k]\n",
    "\n",
    "        b = j[j.band == 'B']\n",
    "        B = np.average(b['magnitude'])\n",
    "        B = B - 0.527 - dmod\n",
    "        B_err= np.average(b['e_magnitude'])\n",
    "\n",
    "        v = j[j.band == 'V']\n",
    "        V = np.average(v['magnitude'])\n",
    "        V = V - 0.399 - dmod\n",
    "        V_err = np.average(v['e_magnitude'])    \n",
    "\n",
    "        r = j[j.band == \"r'\"]\n",
    "        R = np.average(r['magnitude'])\n",
    "        R = R - 0.332 - dmod\n",
    "        R_err = np.average(r['e_magnitude'])\n",
    "\n",
    "        i = j[j.band == \"i'\"]\n",
    "        I = np.average(i['magnitude'])\n",
    "        I = I - 0.247 - dmod\n",
    "        I_err = np.average(i['e_magnitude'])  \n",
    "\n",
    "        file1.writelines([str(k)+'\\t', str(B)+'\\t', str(B_err)+'\\t', str(V)+'\\t', str(V_err)+'\\t', str(R)+'\\t', str(R_err)+'\\t', str(I)+'\\t', str(I_err)+'\\t \\n'])    \n",
    "    \n",
    "    file1.close()\n",
    "        \n",
    "    file2 = open('SN2006ajlt_BVRI.txt', 'w+')  \n",
    "        \n",
    "    for k in data_lt.time.unique():\n",
    "        j = data_lt[data_lt.time == k]\n",
    "        \n",
    "        b = j[j.band == 'Johnson B']\n",
    "        B = np.average(b['m_avg'])\n",
    "        B = B - 0.527 - dmod\n",
    "        B_err= np.average(b['sigma_m_avg'])\n",
    "\n",
    "        v = j[j.band == 'WFPC2 V']\n",
    "        V = np.average(v['m_avg'])\n",
    "        V = V - 0.399 - dmod\n",
    "        V_err = np.average(v['sigma_m_avg'])    \n",
    "\n",
    "        r = j[j.band == \"SDSS r'\"]\n",
    "        R = np.average(r['m_avg'])\n",
    "        R = R - 0.332 - dmod\n",
    "        R_err = np.average(r['sigma_m_avg'])\n",
    "\n",
    "        i = j[j.band == 'Wfpc 2 Wide I']\n",
    "        I = np.average(i['m_avg'])\n",
    "        I = I - 0.219 - dmod\n",
    "        I_err = np.average(i['sigma_m_avg'])  \n",
    "\n",
    "        file2.writelines([str(k)+'\\t', str(B)+'\\t', str(B_err)+'\\t', str(V)+'\\t', str(V_err)+'\\t', str(R)+'\\t', str(R_err)+'\\t', str(I)+'\\t', str(I_err)+'\\t \\n'])    \n",
    "    \n",
    "\n",
    "    file2.close()\n",
    "    \n",
    "    return srcs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.87755906681724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2014Ap&SS.354...89B',\n",
       " '2014ApJS..213...19B',\n",
       " '2006ApJ...645L..21M,CfA Supernova Archive']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_for_superbol_2006aj(SN2006aj,SN2006aj_lt,149.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
